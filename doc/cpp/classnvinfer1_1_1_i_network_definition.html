<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>TensorRT: nvinfer1::INetworkDefinition Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">TensorRT
   &#160;<span id="projectnumber">6.0.1.8</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('classnvinfer1_1_1_i_network_definition.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classnvinfer1_1_1_i_network_definition-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">nvinfer1::INetworkDefinition Class Reference<span class="mlabels"><span class="mlabel">abstract</span></span></div>  </div>
</div><!--header-->
<div class="contents">

<p>A network definition for input to the builder.  
 <a href="classnvinfer1_1_1_i_network_definition.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_nv_infer_8h_source.html">NvInfer.h</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a06a61f560bdf6197afd3368937f62025"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a06a61f560bdf6197afd3368937f62025">addInput</a> (const char *name, <a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217">DataType</a> type, <a class="el" href="classnvinfer1_1_1_dims.html">Dims</a> dimensions)=0</td></tr>
<tr class="memdesc:a06a61f560bdf6197afd3368937f62025"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add an input tensor to the network.  <a href="#a06a61f560bdf6197afd3368937f62025">More...</a><br /></td></tr>
<tr class="separator:a06a61f560bdf6197afd3368937f62025"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d2cdec24bc4a1507fc80f100e18cfe9"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a5d2cdec24bc4a1507fc80f100e18cfe9">markOutput</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;tensor)=0</td></tr>
<tr class="memdesc:a5d2cdec24bc4a1507fc80f100e18cfe9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Mark a tensor as a network output.  <a href="#a5d2cdec24bc4a1507fc80f100e18cfe9">More...</a><br /></td></tr>
<tr class="separator:a5d2cdec24bc4a1507fc80f100e18cfe9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a29fb055009bb117be0e957cd1bce44a9"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_convolution_layer.html">IConvolutionLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a29fb055009bb117be0e957cd1bce44a9">addConvolution</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, int nbOutputMaps, <a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a> kernelSize, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> kernelWeights, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> biasWeights)=0</td></tr>
<tr class="memdesc:a29fb055009bb117be0e957cd1bce44a9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a convolution layer to the network.  <a href="#a29fb055009bb117be0e957cd1bce44a9">More...</a><br /></td></tr>
<tr class="separator:a29fb055009bb117be0e957cd1bce44a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a411e2cefb9a4307d99fcc442c2a708a8"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_fully_connected_layer.html">IFullyConnectedLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a411e2cefb9a4307d99fcc442c2a708a8">addFullyConnected</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, int nbOutputs, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> kernelWeights, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> biasWeights)=0</td></tr>
<tr class="memdesc:a411e2cefb9a4307d99fcc442c2a708a8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a fully connected layer to the network.  <a href="#a411e2cefb9a4307d99fcc442c2a708a8">More...</a><br /></td></tr>
<tr class="separator:a411e2cefb9a4307d99fcc442c2a708a8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0382282a59e3841726f6c29c4ac1f684"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_activation_layer.html">IActivationLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a0382282a59e3841726f6c29c4ac1f684">addActivation</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="namespacenvinfer1.html#acbd177748000d30ae0277ee980757eb6">ActivationType</a> type)=0</td></tr>
<tr class="memdesc:a0382282a59e3841726f6c29c4ac1f684"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add an activation layer to the network.  <a href="#a0382282a59e3841726f6c29c4ac1f684">More...</a><br /></td></tr>
<tr class="separator:a0382282a59e3841726f6c29c4ac1f684"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a49459eaa7e1bbff5371365f125c2f0c5"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_pooling_layer.html">IPoolingLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a49459eaa7e1bbff5371365f125c2f0c5">addPooling</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="namespacenvinfer1.html#aaebe16cb048ecf44524d17aaf9eaac14">PoolingType</a> type, <a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a> windowSize)=0</td></tr>
<tr class="memdesc:a49459eaa7e1bbff5371365f125c2f0c5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a pooling layer to the network.  <a href="#a49459eaa7e1bbff5371365f125c2f0c5">More...</a><br /></td></tr>
<tr class="separator:a49459eaa7e1bbff5371365f125c2f0c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa1c8386fd389fd74b0b48121d22abc67"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_l_r_n_layer.html">ILRNLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aa1c8386fd389fd74b0b48121d22abc67">addLRN</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, int window, float alpha, float beta, float k)=0</td></tr>
<tr class="memdesc:aa1c8386fd389fd74b0b48121d22abc67"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a LRN layer to the network.  <a href="#aa1c8386fd389fd74b0b48121d22abc67">More...</a><br /></td></tr>
<tr class="separator:aa1c8386fd389fd74b0b48121d22abc67"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37cf24c7c620aa661de167f302559289"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_scale_layer.html">IScaleLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a37cf24c7c620aa661de167f302559289">addScale</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="namespacenvinfer1.html#aa718ced5536f804059d1c9ab7b9489d0">ScaleMode</a> mode, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> shift, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> scale, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> power)=0</td></tr>
<tr class="memdesc:a37cf24c7c620aa661de167f302559289"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a Scale layer to the network.  <a href="#a37cf24c7c620aa661de167f302559289">More...</a><br /></td></tr>
<tr class="separator:a37cf24c7c620aa661de167f302559289"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a595af67528bf0664afa9815114933320"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_soft_max_layer.html">ISoftMaxLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a595af67528bf0664afa9815114933320">addSoftMax</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input)=0</td></tr>
<tr class="memdesc:a595af67528bf0664afa9815114933320"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a SoftMax layer to the network.  <a href="#a595af67528bf0664afa9815114933320">More...</a><br /></td></tr>
<tr class="separator:a595af67528bf0664afa9815114933320"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80d81ac3ebb81efbd3a29d4c9f5c3a72"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_concatenation_layer.html">IConcatenationLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a80d81ac3ebb81efbd3a29d4c9f5c3a72">addConcatenation</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *const *inputs, int nbInputs)=0</td></tr>
<tr class="memdesc:a80d81ac3ebb81efbd3a29d4c9f5c3a72"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a concatenation layer to the network.  <a href="#a80d81ac3ebb81efbd3a29d4c9f5c3a72">More...</a><br /></td></tr>
<tr class="separator:a80d81ac3ebb81efbd3a29d4c9f5c3a72"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a80f985a0a5e5e68561ef205bf346fc33"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_deconvolution_layer.html">IDeconvolutionLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a80f985a0a5e5e68561ef205bf346fc33">addDeconvolution</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, int nbOutputMaps, <a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a> kernelSize, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> kernelWeights, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> biasWeights)=0</td></tr>
<tr class="memdesc:a80f985a0a5e5e68561ef205bf346fc33"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a deconvolution layer to the network.  <a href="#a80f985a0a5e5e68561ef205bf346fc33">More...</a><br /></td></tr>
<tr class="separator:a80f985a0a5e5e68561ef205bf346fc33"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa12fda7cb22a7a12f4d58701e9f3988f"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_element_wise_layer.html">IElementWiseLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aa12fda7cb22a7a12f4d58701e9f3988f">addElementWise</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input1, <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input2, <a class="el" href="namespacenvinfer1.html#a9badc834875b5c57d9556a66e5e20978">ElementWiseOperation</a> op)=0</td></tr>
<tr class="memdesc:aa12fda7cb22a7a12f4d58701e9f3988f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add an elementwise layer to the network.  <a href="#aa12fda7cb22a7a12f4d58701e9f3988f">More...</a><br /></td></tr>
<tr class="separator:aa12fda7cb22a7a12f4d58701e9f3988f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c01c498d5adf7d48077827cc9c09021"><td class="memItemLeft" align="right" valign="top">virtual TRT_DEPRECATED <a class="el" href="classnvinfer1_1_1_i_r_n_n_layer.html">IRNNLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a7c01c498d5adf7d48077827cc9c09021">addRNN</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;inputs, int layerCount, std::size_t hiddenSize, int maxSeqLen, <a class="el" href="namespacenvinfer1.html#ace7b656a1c0537ea0edd17cf61121200">RNNOperation</a> op, <a class="el" href="namespacenvinfer1.html#a1c31bdeeb9aa6bcffeb71cc5a3f126fd">RNNInputMode</a> mode, <a class="el" href="namespacenvinfer1.html#abda12e12ae04a971df63667dc4df99d8">RNNDirection</a> dir, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> weights, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> bias)=0</td></tr>
<tr class="memdesc:a7c01c498d5adf7d48077827cc9c09021"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add an <code>layerCount</code> deep RNN layer to the network with a sequence length of <code>maxSeqLen</code> and <code>hiddenSize</code> internal state per layer.  <a href="#a7c01c498d5adf7d48077827cc9c09021">More...</a><br /></td></tr>
<tr class="separator:a7c01c498d5adf7d48077827cc9c09021"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a87b5de1bc69c2043bce27bca786b5c6b"><td class="memItemLeft" align="right" valign="top">virtual TRT_DEPRECATED <a class="el" href="classnvinfer1_1_1_i_plugin_layer.html">IPluginLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a87b5de1bc69c2043bce27bca786b5c6b">addPlugin</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *const *inputs, int nbInputs, <a class="el" href="classnvinfer1_1_1_i_plugin.html">IPlugin</a> &amp;plugin)=0</td></tr>
<tr class="memdesc:a87b5de1bc69c2043bce27bca786b5c6b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a plugin layer to the network.  <a href="#a87b5de1bc69c2043bce27bca786b5c6b">More...</a><br /></td></tr>
<tr class="separator:a87b5de1bc69c2043bce27bca786b5c6b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4b85bd3f05c234fcc1118f827d7c0720"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_unary_layer.html">IUnaryLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a4b85bd3f05c234fcc1118f827d7c0720">addUnary</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="namespacenvinfer1.html#aeaeaae08a730508ead278d52b8517a09">UnaryOperation</a> operation)=0</td></tr>
<tr class="memdesc:a4b85bd3f05c234fcc1118f827d7c0720"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a unary layer to the network.  <a href="#a4b85bd3f05c234fcc1118f827d7c0720">More...</a><br /></td></tr>
<tr class="separator:a4b85bd3f05c234fcc1118f827d7c0720"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a334d849cb8720a8a66a95fc84487b132"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_padding_layer.html">IPaddingLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a334d849cb8720a8a66a95fc84487b132">addPadding</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a> prePadding, <a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a> postPadding)=0</td></tr>
<tr class="memdesc:a334d849cb8720a8a66a95fc84487b132"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a padding layer to the network.  <a href="#a334d849cb8720a8a66a95fc84487b132">More...</a><br /></td></tr>
<tr class="separator:a334d849cb8720a8a66a95fc84487b132"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2628a97544b7802076246069321e2bf9"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_shuffle_layer.html">IShuffleLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a2628a97544b7802076246069321e2bf9">addShuffle</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input)=0</td></tr>
<tr class="memdesc:a2628a97544b7802076246069321e2bf9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a shuffle layer to the network.  <a href="#a2628a97544b7802076246069321e2bf9">More...</a><br /></td></tr>
<tr class="separator:a2628a97544b7802076246069321e2bf9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a402ad2fbbf572f592077c6c0ea12a51f"><td class="memItemLeft" align="right" valign="top">virtual TRT_DEPRECATED void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a402ad2fbbf572f592077c6c0ea12a51f">setPoolingOutputDimensionsFormula</a> (<a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> *formula)=0</td></tr>
<tr class="memdesc:a402ad2fbbf572f592077c6c0ea12a51f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the pooling output dimensions formula.  <a href="#a402ad2fbbf572f592077c6c0ea12a51f">More...</a><br /></td></tr>
<tr class="separator:a402ad2fbbf572f592077c6c0ea12a51f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa0c2ec41c0a88e6f69bad7fa910baea6"><td class="memItemLeft" align="right" valign="top">virtual TRT_DEPRECATED <a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aa0c2ec41c0a88e6f69bad7fa910baea6">getPoolingOutputDimensionsFormula</a> () const =0</td></tr>
<tr class="memdesc:aa0c2ec41c0a88e6f69bad7fa910baea6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the pooling output dimensions formula.  <a href="#aa0c2ec41c0a88e6f69bad7fa910baea6">More...</a><br /></td></tr>
<tr class="separator:aa0c2ec41c0a88e6f69bad7fa910baea6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab83e073d7230aefc36f1ce2168da24c3"><td class="memItemLeft" align="right" valign="top">virtual TRT_DEPRECATED void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#ab83e073d7230aefc36f1ce2168da24c3">setConvolutionOutputDimensionsFormula</a> (<a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> *formula)=0</td></tr>
<tr class="memdesc:ab83e073d7230aefc36f1ce2168da24c3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the convolution output dimensions formula.  <a href="#ab83e073d7230aefc36f1ce2168da24c3">More...</a><br /></td></tr>
<tr class="separator:ab83e073d7230aefc36f1ce2168da24c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adb198d5371d6ed8488708f319232f5ba"><td class="memItemLeft" align="right" valign="top">virtual TRT_DEPRECATED <a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#adb198d5371d6ed8488708f319232f5ba">getConvolutionOutputDimensionsFormula</a> () const =0</td></tr>
<tr class="memdesc:adb198d5371d6ed8488708f319232f5ba"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the convolution output dimensions formula.  <a href="#adb198d5371d6ed8488708f319232f5ba">More...</a><br /></td></tr>
<tr class="separator:adb198d5371d6ed8488708f319232f5ba"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a34b77e89e6fca477d4ad24b8461b9633"><td class="memItemLeft" align="right" valign="top">virtual TRT_DEPRECATED void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a34b77e89e6fca477d4ad24b8461b9633">setDeconvolutionOutputDimensionsFormula</a> (<a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> *formula)=0</td></tr>
<tr class="memdesc:a34b77e89e6fca477d4ad24b8461b9633"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set the deconvolution output dimensions formula.  <a href="#a34b77e89e6fca477d4ad24b8461b9633">More...</a><br /></td></tr>
<tr class="separator:a34b77e89e6fca477d4ad24b8461b9633"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61198efbae4b7573052fc6be4b1a59ed"><td class="memItemLeft" align="right" valign="top">virtual TRT_DEPRECATED <a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a61198efbae4b7573052fc6be4b1a59ed">getDeconvolutionOutputDimensionsFormula</a> () const =0</td></tr>
<tr class="memdesc:a61198efbae4b7573052fc6be4b1a59ed"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the deconvolution output dimensions formula.  <a href="#a61198efbae4b7573052fc6be4b1a59ed">More...</a><br /></td></tr>
<tr class="separator:a61198efbae4b7573052fc6be4b1a59ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a191a7724fc0c03a3b6f5fd8782dcd30e"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a191a7724fc0c03a3b6f5fd8782dcd30e">getNbLayers</a> () const =0</td></tr>
<tr class="memdesc:a191a7724fc0c03a3b6f5fd8782dcd30e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the number of layers in the network.  <a href="#a191a7724fc0c03a3b6f5fd8782dcd30e">More...</a><br /></td></tr>
<tr class="separator:a191a7724fc0c03a3b6f5fd8782dcd30e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a81749aaa08e93ca4ae1dbb1739c7bd"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_layer.html">ILayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a4a81749aaa08e93ca4ae1dbb1739c7bd">getLayer</a> (int index) const =0</td></tr>
<tr class="memdesc:a4a81749aaa08e93ca4ae1dbb1739c7bd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the layer specified by the given index.  <a href="#a4a81749aaa08e93ca4ae1dbb1739c7bd">More...</a><br /></td></tr>
<tr class="separator:a4a81749aaa08e93ca4ae1dbb1739c7bd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac7a0538c92b9850b3ecd939609759cdd"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#ac7a0538c92b9850b3ecd939609759cdd">getNbInputs</a> () const =0</td></tr>
<tr class="memdesc:ac7a0538c92b9850b3ecd939609759cdd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the number of inputs in the network.  <a href="#ac7a0538c92b9850b3ecd939609759cdd">More...</a><br /></td></tr>
<tr class="separator:ac7a0538c92b9850b3ecd939609759cdd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaecdd8775e0ce4643112932f721f93c1"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aaecdd8775e0ce4643112932f721f93c1">getInput</a> (int index) const =0</td></tr>
<tr class="memdesc:aaecdd8775e0ce4643112932f721f93c1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the input tensor specified by the given index.  <a href="#aaecdd8775e0ce4643112932f721f93c1">More...</a><br /></td></tr>
<tr class="separator:aaecdd8775e0ce4643112932f721f93c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1eb3e1df9e652363d7ab4e3796794bb2"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a1eb3e1df9e652363d7ab4e3796794bb2">getNbOutputs</a> () const =0</td></tr>
<tr class="memdesc:a1eb3e1df9e652363d7ab4e3796794bb2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the number of outputs in the network.  <a href="#a1eb3e1df9e652363d7ab4e3796794bb2">More...</a><br /></td></tr>
<tr class="separator:a1eb3e1df9e652363d7ab4e3796794bb2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6eb45e378bf2b2097da64e3886010bd0"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a6eb45e378bf2b2097da64e3886010bd0">getOutput</a> (int index) const =0</td></tr>
<tr class="memdesc:a6eb45e378bf2b2097da64e3886010bd0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the output tensor specified by the given index.  <a href="#a6eb45e378bf2b2097da64e3886010bd0">More...</a><br /></td></tr>
<tr class="separator:a6eb45e378bf2b2097da64e3886010bd0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a42e5fd7a24306239e67168435a800515"><td class="memItemLeft" align="right" valign="top"><a id="a42e5fd7a24306239e67168435a800515"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a42e5fd7a24306239e67168435a800515">destroy</a> ()=0</td></tr>
<tr class="memdesc:a42e5fd7a24306239e67168435a800515"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destroy this <a class="el" href="classnvinfer1_1_1_i_network_definition.html" title="A network definition for input to the builder. ">INetworkDefinition</a> object. <br /></td></tr>
<tr class="separator:a42e5fd7a24306239e67168435a800515"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a41437aa7107e61b82c5f3490984bf011"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_reduce_layer.html">IReduceLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a41437aa7107e61b82c5f3490984bf011">addReduce</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="namespacenvinfer1.html#a6640220fcbd633240524ba27b5c6c7e7">ReduceOperation</a> operation, uint32_t reduceAxes, bool keepDimensions)=0</td></tr>
<tr class="memdesc:a41437aa7107e61b82c5f3490984bf011"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a reduce layer to the network.  <a href="#a41437aa7107e61b82c5f3490984bf011">More...</a><br /></td></tr>
<tr class="separator:a41437aa7107e61b82c5f3490984bf011"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a384a409318bf416be3aa4442f2b0ce76"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_top_k_layer.html">ITopKLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a384a409318bf416be3aa4442f2b0ce76">addTopK</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="namespacenvinfer1.html#a1323342950a2702ba66e29c64404a7f3">TopKOperation</a> op, int k, uint32_t reduceAxes)=0</td></tr>
<tr class="memdesc:a384a409318bf416be3aa4442f2b0ce76"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a TopK layer to the network.  <a href="#a384a409318bf416be3aa4442f2b0ce76">More...</a><br /></td></tr>
<tr class="separator:a384a409318bf416be3aa4442f2b0ce76"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a81ea0b5ce4a6a24e8e4953fd0e0b3216"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_gather_layer.html">IGatherLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a81ea0b5ce4a6a24e8e4953fd0e0b3216">addGather</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;data, <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;indices, int axis)=0</td></tr>
<tr class="memdesc:a81ea0b5ce4a6a24e8e4953fd0e0b3216"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a gather layer to the network.  <a href="#a81ea0b5ce4a6a24e8e4953fd0e0b3216">More...</a><br /></td></tr>
<tr class="separator:a81ea0b5ce4a6a24e8e4953fd0e0b3216"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aea842c9f897201eb855ce164944e9110"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_ragged_soft_max_layer.html">IRaggedSoftMaxLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aea842c9f897201eb855ce164944e9110">addRaggedSoftMax</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;bounds)=0</td></tr>
<tr class="memdesc:aea842c9f897201eb855ce164944e9110"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a RaggedSoftMax layer to the network.  <a href="#aea842c9f897201eb855ce164944e9110">More...</a><br /></td></tr>
<tr class="separator:aea842c9f897201eb855ce164944e9110"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7643943f07380269f3361a0aa5620535"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_matrix_multiply_layer.html">IMatrixMultiplyLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a7643943f07380269f3361a0aa5620535">addMatrixMultiply</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input0, <a class="el" href="namespacenvinfer1.html#a9ad4a5ef323b8a421ecad9678cd183d2">MatrixOperation</a> op0, <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input1, <a class="el" href="namespacenvinfer1.html#a9ad4a5ef323b8a421ecad9678cd183d2">MatrixOperation</a> op1)=0</td></tr>
<tr class="memdesc:a7643943f07380269f3361a0aa5620535"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a MatrixMultiply layer to the network.  <a href="#a7643943f07380269f3361a0aa5620535">More...</a><br /></td></tr>
<tr class="separator:a7643943f07380269f3361a0aa5620535"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6197f3576f446c22c3b60ef60e9e8c62"><td class="memItemLeft" align="right" valign="top">virtual TRT_DEPRECATED <a class="el" href="classnvinfer1_1_1_i_matrix_multiply_layer.html">IMatrixMultiplyLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a6197f3576f446c22c3b60ef60e9e8c62">addMatrixMultiply</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input0, bool transpose0, <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input1, bool transpose1)=0</td></tr>
<tr class="memdesc:a6197f3576f446c22c3b60ef60e9e8c62"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a MatrixMultiply layer to the network.  <a href="#a6197f3576f446c22c3b60ef60e9e8c62">More...</a><br /></td></tr>
<tr class="separator:a6197f3576f446c22c3b60ef60e9e8c62"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec3314208c6d807cb572cd7d336bf5ed"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_constant_layer.html">IConstantLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aec3314208c6d807cb572cd7d336bf5ed">addConstant</a> (<a class="el" href="classnvinfer1_1_1_dims.html">Dims</a> dimensions, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> weights)=0</td></tr>
<tr class="memdesc:aec3314208c6d807cb572cd7d336bf5ed"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a constant layer to the network.  <a href="#aec3314208c6d807cb572cd7d336bf5ed">More...</a><br /></td></tr>
<tr class="separator:aec3314208c6d807cb572cd7d336bf5ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6cd3869f7406f73261857987be1b18a9"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html">IRNNv2Layer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a6cd3869f7406f73261857987be1b18a9">addRNNv2</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, int32_t layerCount, int32_t hiddenSize, int32_t maxSeqLen, <a class="el" href="namespacenvinfer1.html#ace7b656a1c0537ea0edd17cf61121200">RNNOperation</a> op)=0</td></tr>
<tr class="memdesc:a6cd3869f7406f73261857987be1b18a9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add an <code>layerCount</code> deep RNN layer to the network with <code>hiddenSize</code> internal states that can take a batch with fixed or variable sequence lengths.  <a href="#a6cd3869f7406f73261857987be1b18a9">More...</a><br /></td></tr>
<tr class="separator:a6cd3869f7406f73261857987be1b18a9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5f92ffc2baf52db159d1400b549c478"><td class="memItemLeft" align="right" valign="top">virtual TRT_DEPRECATED <a class="el" href="classnvinfer1_1_1_i_plugin_layer.html">IPluginLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#ae5f92ffc2baf52db159d1400b549c478">addPluginExt</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *const *inputs, int nbInputs, <a class="el" href="classnvinfer1_1_1_i_plugin_ext.html">IPluginExt</a> &amp;plugin)=0</td></tr>
<tr class="memdesc:ae5f92ffc2baf52db159d1400b549c478"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a plugin layer to the network using an <a class="el" href="classnvinfer1_1_1_i_plugin_ext.html" title="Plugin class for user-implemented layers. ">IPluginExt</a> interface.  <a href="#ae5f92ffc2baf52db159d1400b549c478">More...</a><br /></td></tr>
<tr class="separator:ae5f92ffc2baf52db159d1400b549c478"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01811cfea946a80324a5538667e2a427"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_identity_layer.html">IIdentityLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a01811cfea946a80324a5538667e2a427">addIdentity</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input)=0</td></tr>
<tr class="memdesc:a01811cfea946a80324a5538667e2a427"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add an identity layer.  <a href="#a01811cfea946a80324a5538667e2a427">More...</a><br /></td></tr>
<tr class="separator:a01811cfea946a80324a5538667e2a427"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a17e88f382119792187af786c3cc83770"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a17e88f382119792187af786c3cc83770">removeTensor</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;tensor)=0</td></tr>
<tr class="memdesc:a17e88f382119792187af786c3cc83770"><td class="mdescLeft">&#160;</td><td class="mdescRight">remove a tensor from the network definition.  <a href="#a17e88f382119792187af786c3cc83770">More...</a><br /></td></tr>
<tr class="separator:a17e88f382119792187af786c3cc83770"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a31e43047aa9ec0021f777373a56ef3a0"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a31e43047aa9ec0021f777373a56ef3a0">unmarkOutput</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;tensor)=0</td></tr>
<tr class="memdesc:a31e43047aa9ec0021f777373a56ef3a0"><td class="mdescLeft">&#160;</td><td class="mdescRight">unmark a tensor as a network output.  <a href="#a31e43047aa9ec0021f777373a56ef3a0">More...</a><br /></td></tr>
<tr class="separator:a31e43047aa9ec0021f777373a56ef3a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c6e2a0b4e1c8a4df1722a24cc7c0473"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_plugin_v2_layer.html">IPluginV2Layer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a0c6e2a0b4e1c8a4df1722a24cc7c0473">addPluginV2</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *const *inputs, int nbInputs, <a class="el" href="classnvinfer1_1_1_i_plugin_v2.html">IPluginV2</a> &amp;plugin)=0</td></tr>
<tr class="memdesc:a0c6e2a0b4e1c8a4df1722a24cc7c0473"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a plugin layer to the network using the <a class="el" href="classnvinfer1_1_1_i_plugin_v2.html" title="Plugin class for user-implemented layers. ">IPluginV2</a> interface.  <a href="#a0c6e2a0b4e1c8a4df1722a24cc7c0473">More...</a><br /></td></tr>
<tr class="separator:a0c6e2a0b4e1c8a4df1722a24cc7c0473"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab3d64683b10afdbc944075da818fb086"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_slice_layer.html">ISliceLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#ab3d64683b10afdbc944075da818fb086">addSlice</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="classnvinfer1_1_1_dims.html">Dims</a> start, <a class="el" href="classnvinfer1_1_1_dims.html">Dims</a> size, <a class="el" href="classnvinfer1_1_1_dims.html">Dims</a> stride)=0</td></tr>
<tr class="memdesc:ab3d64683b10afdbc944075da818fb086"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a slice layer to the network.  <a href="#ab3d64683b10afdbc944075da818fb086">More...</a><br /></td></tr>
<tr class="separator:ab3d64683b10afdbc944075da818fb086"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2d3ffd5af77299ca45ab7a286e21eaef"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a2d3ffd5af77299ca45ab7a286e21eaef">setName</a> (const char *name)=0</td></tr>
<tr class="memdesc:a2d3ffd5af77299ca45ab7a286e21eaef"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the name of the network.  <a href="#a2d3ffd5af77299ca45ab7a286e21eaef">More...</a><br /></td></tr>
<tr class="separator:a2d3ffd5af77299ca45ab7a286e21eaef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6b53187d680c53e89c19cd39bc66beb"><td class="memItemLeft" align="right" valign="top">virtual const char *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#ae6b53187d680c53e89c19cd39bc66beb">getName</a> () const =0</td></tr>
<tr class="memdesc:ae6b53187d680c53e89c19cd39bc66beb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the name associated with the network.  <a href="#ae6b53187d680c53e89c19cd39bc66beb">More...</a><br /></td></tr>
<tr class="separator:ae6b53187d680c53e89c19cd39bc66beb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab4eccbfe457683551e68106b827b1f9d"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_shape_layer.html">IShapeLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#ab4eccbfe457683551e68106b827b1f9d">addShape</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input)=0</td></tr>
<tr class="memdesc:ab4eccbfe457683551e68106b827b1f9d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a shape layer to the network.  <a href="#ab4eccbfe457683551e68106b827b1f9d">More...</a><br /></td></tr>
<tr class="separator:ab4eccbfe457683551e68106b827b1f9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa4373cda43b868d9e4c8f3d862f4d7aa"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aa4373cda43b868d9e4c8f3d862f4d7aa">hasImplicitBatchDimension</a> () const =0</td></tr>
<tr class="memdesc:aa4373cda43b868d9e4c8f3d862f4d7aa"><td class="mdescLeft">&#160;</td><td class="mdescRight">True if tensors have implicit batch dimension.  <a href="#aa4373cda43b868d9e4c8f3d862f4d7aa">More...</a><br /></td></tr>
<tr class="separator:aa4373cda43b868d9e4c8f3d862f4d7aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f0fff6e9c2469e31ac3be82dd3f0f28"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a1f0fff6e9c2469e31ac3be82dd3f0f28">markOutputForShapes</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;tensor)=0</td></tr>
<tr class="memdesc:a1f0fff6e9c2469e31ac3be82dd3f0f28"><td class="mdescLeft">&#160;</td><td class="mdescRight">Enable tensor's value to be computed by <a class="el" href="classnvinfer1_1_1_i_execution_context.html#a3afb239c59299f5e88a617781d294d44" title="Get values of an input tensor required for shape calculations or an output tensor produced by shape c...">IExecutionContext::getShapeBinding</a>.  <a href="#a1f0fff6e9c2469e31ac3be82dd3f0f28">More...</a><br /></td></tr>
<tr class="separator:a1f0fff6e9c2469e31ac3be82dd3f0f28"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9f14e1d5c28329ab51f99309b84d205c"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a9f14e1d5c28329ab51f99309b84d205c">unmarkOutputForShapes</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;tensor)=0</td></tr>
<tr class="memdesc:a9f14e1d5c28329ab51f99309b84d205c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Undo markOutputForShapes.  <a href="#a9f14e1d5c28329ab51f99309b84d205c">More...</a><br /></td></tr>
<tr class="separator:a9f14e1d5c28329ab51f99309b84d205c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a966d57cbe9f10ebf65462d6dd53141b1"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_parametric_re_l_u_layer.html">IParametricReLULayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a966d57cbe9f10ebf65462d6dd53141b1">addParametricReLU</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;slope) noexcept=0</td></tr>
<tr class="memdesc:a966d57cbe9f10ebf65462d6dd53141b1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a parametric ReLU layer to the network.  <a href="#a966d57cbe9f10ebf65462d6dd53141b1">More...</a><br /></td></tr>
<tr class="separator:a966d57cbe9f10ebf65462d6dd53141b1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a108f9f6d884e642a9e3812b5175fbc55"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_convolution_layer.html">IConvolutionLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a108f9f6d884e642a9e3812b5175fbc55">addConvolutionNd</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, int nbOutputMaps, <a class="el" href="classnvinfer1_1_1_dims.html">Dims</a> kernelSize, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> kernelWeights, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> biasWeights)=0</td></tr>
<tr class="memdesc:a108f9f6d884e642a9e3812b5175fbc55"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a multi-dimension convolution layer to the network.  <a href="#a108f9f6d884e642a9e3812b5175fbc55">More...</a><br /></td></tr>
<tr class="separator:a108f9f6d884e642a9e3812b5175fbc55"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9bf1bc8eab4861a6203c090c8ba3d819"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_pooling_layer.html">IPoolingLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a9bf1bc8eab4861a6203c090c8ba3d819">addPoolingNd</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="namespacenvinfer1.html#aaebe16cb048ecf44524d17aaf9eaac14">PoolingType</a> type, <a class="el" href="classnvinfer1_1_1_dims.html">Dims</a> windowSize)=0</td></tr>
<tr class="memdesc:a9bf1bc8eab4861a6203c090c8ba3d819"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a multi-dimension pooling layer to the network.  <a href="#a9bf1bc8eab4861a6203c090c8ba3d819">More...</a><br /></td></tr>
<tr class="separator:a9bf1bc8eab4861a6203c090c8ba3d819"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a64423656a50a3bff760743e371e53dff"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_deconvolution_layer.html">IDeconvolutionLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a64423656a50a3bff760743e371e53dff">addDeconvolutionNd</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, int nbOutputMaps, <a class="el" href="classnvinfer1_1_1_dims.html">Dims</a> kernelSize, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> kernelWeights, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> biasWeights)=0</td></tr>
<tr class="memdesc:a64423656a50a3bff760743e371e53dff"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a multi-dimension deconvolution layer to the network.  <a href="#a64423656a50a3bff760743e371e53dff">More...</a><br /></td></tr>
<tr class="separator:a64423656a50a3bff760743e371e53dff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa2af68900fe0f5635b63212eaa3c4324"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_scale_layer.html">IScaleLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aa2af68900fe0f5635b63212eaa3c4324">addScaleNd</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input, <a class="el" href="namespacenvinfer1.html#aa718ced5536f804059d1c9ab7b9489d0">ScaleMode</a> mode, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> shift, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> scale, <a class="el" href="classnvinfer1_1_1_weights.html">Weights</a> power, int channelAxis)=0</td></tr>
<tr class="memdesc:aa2af68900fe0f5635b63212eaa3c4324"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a multi-dimension scale layer to the network.  <a href="#aa2af68900fe0f5635b63212eaa3c4324">More...</a><br /></td></tr>
<tr class="separator:aa2af68900fe0f5635b63212eaa3c4324"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a12b4eb2416951d1f575d3fc263395bb9"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="classnvinfer1_1_1_i_resize_layer.html">IResizeLayer</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a12b4eb2416951d1f575d3fc263395bb9">addResize</a> (<a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;input)=0</td></tr>
<tr class="memdesc:a12b4eb2416951d1f575d3fc263395bb9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add a resize layer to the network.  <a href="#a12b4eb2416951d1f575d3fc263395bb9">More...</a><br /></td></tr>
<tr class="separator:a12b4eb2416951d1f575d3fc263395bb9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a46f05bc0dcd87790b406c3301ccc1e7d"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a46f05bc0dcd87790b406c3301ccc1e7d">hasExplicitPrecision</a> () const =0</td></tr>
<tr class="memdesc:a46f05bc0dcd87790b406c3301ccc1e7d"><td class="mdescLeft">&#160;</td><td class="mdescRight">True if network is an explicit precision network.  <a href="#a46f05bc0dcd87790b406c3301ccc1e7d">More...</a><br /></td></tr>
<tr class="separator:a46f05bc0dcd87790b406c3301ccc1e7d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>A network definition for input to the builder. </p>
<p>A network definition defines the structure of the network, and combined with a <a class="el" href="classnvinfer1_1_1_i_builder_config.html" title="Holds properties for configuring a builder to produce an engine. ">IBuilderConfig</a>, is built into an engine using an <a class="el" href="classnvinfer1_1_1_i_builder.html" title="Builds an engine from a network definition. ">IBuilder</a>. An <a class="el" href="classnvinfer1_1_1_i_network_definition.html" title="A network definition for input to the builder. ">INetworkDefinition</a> can either have an implicit batch dimensions, specified at runtime, or all dimensions explicit, full dims mode, in the network definition. When a network has been created using createNetwork(), only implicit batch size mode is supported. The function hasImplicitBatchSize() is used to query the mode of the network.</p>
<p>A network with implicit batch dimensions returns the dimensions of a layer without the implicit dimension, and instead the batch is specified at execute/enqueue time. If the network has all dimensions specified, then the first dimension follows elementwise broadcast rules: if it is 1 for some inputs and is some value N for all other inputs, then the first dimension of each outut is N, and the inputs with 1 for the first dimension are broadcast. Having divergent batch sizes across inputs to a layer is not supported.</p>
<dl class="section warning"><dt>Warning</dt><dd>Do not inherit from this class, as doing so will break forward-compatibility of the API and ABI. </dd></dl>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a0382282a59e3841726f6c29c4ac1f684"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0382282a59e3841726f6c29c4ac1f684">&#9670;&nbsp;</a></span>addActivation()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_activation_layer.html">IActivationLayer</a>* nvinfer1::INetworkDefinition::addActivation </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#acbd177748000d30ae0277ee980757eb6">ActivationType</a>&#160;</td>
          <td class="paramname"><em>type</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add an activation layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">type</td><td>The type of activation function to apply.</td></tr>
  </table>
  </dd>
</dl>
<p>Note that the setAlpha() and setBeta() methods must be used on the output for activations that require these parameters.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_activation_layer.html" title="An Activation layer in a network definition. ">IActivationLayer</a> <a class="el" href="namespacenvinfer1.html#acbd177748000d30ae0277ee980757eb6" title="Forward declare IGpuAllocator for use in other interfaces. ">ActivationType</a> </dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new activation layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a80d81ac3ebb81efbd3a29d4c9f5c3a72"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a80d81ac3ebb81efbd3a29d4c9f5c3a72">&#9670;&nbsp;</a></span>addConcatenation()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_concatenation_layer.html">IConcatenationLayer</a>* nvinfer1::INetworkDefinition::addConcatenation </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *const *&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbInputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a concatenation layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputs</td><td>The input tensors to the layer. </td></tr>
    <tr><td class="paramname">nbInputs</td><td>The number of input tensors.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_concatenation_layer.html" title="A concatenation layer in a network definition. ">IConcatenationLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new concatenation layer, or nullptr if it could not be created.</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>All tensors must have the same dimensions for all dimensions except for channel. </dd></dl>

</div>
</div>
<a id="aec3314208c6d807cb572cd7d336bf5ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec3314208c6d807cb572cd7d336bf5ed">&#9670;&nbsp;</a></span>addConstant()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_constant_layer.html">IConstantLayer</a>* nvinfer1::INetworkDefinition::addConstant </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims.html">Dims</a>&#160;</td>
          <td class="paramname"><em>dimensions</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>weights</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a constant layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">dimensions</td><td>The dimensions of the constant. </td></tr>
    <tr><td class="paramname">weights</td><td>The constant value, represented as weights.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_constant_layer.html" title="Layer that represents a constant value. ">IConstantLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new constant layer, or nullptr if it could not be created.</dd></dl>
<p>If weights.type is <a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217abd073fcbb15020b25a70e2cd95f9f4a9" title="INT32 format. ">DataType::kINT32</a>, the output is a tensor of 32-bit indices. Otherwise the output is a tensor of real values and the output type will be follow TensorRT's normal precision rules.</p>
<p>If tensors in the network have an implicit batch dimension, the constant is broadcast over that dimension.</p>
<p>If a wildcard dimension is used, the volume of the runtime dimensions must equal the number of weights specified. </p>

</div>
</div>
<a id="a29fb055009bb117be0e957cd1bce44a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a29fb055009bb117be0e957cd1bce44a9">&#9670;&nbsp;</a></span>addConvolution()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_convolution_layer.html">IConvolutionLayer</a>* nvinfer1::INetworkDefinition::addConvolution </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbOutputMaps</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a>&#160;</td>
          <td class="paramname"><em>kernelSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>kernelWeights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>biasWeights</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a convolution layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the convolution. </td></tr>
    <tr><td class="paramname">nbOutputMaps</td><td>The number of output feature maps for the convolution. </td></tr>
    <tr><td class="paramname">kernelSize</td><td>The HW-dimensions of the convolution kernel. </td></tr>
    <tr><td class="paramname">kernelWeights</td><td>The kernel weights for the convolution. </td></tr>
    <tr><td class="paramname">biasWeights</td><td>The optional bias weights for the convolution.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_convolution_layer.html" title="A convolution layer in a network definition. ">IConvolutionLayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>It is an error to specify a wildcard value for the 'C' dimension of the input tensor. </dd>
<dd>
Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new convolution layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a108f9f6d884e642a9e3812b5175fbc55"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a108f9f6d884e642a9e3812b5175fbc55">&#9670;&nbsp;</a></span>addConvolutionNd()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_convolution_layer.html">IConvolutionLayer</a>* nvinfer1::INetworkDefinition::addConvolutionNd </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbOutputMaps</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims.html">Dims</a>&#160;</td>
          <td class="paramname"><em>kernelSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>kernelWeights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>biasWeights</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a multi-dimension convolution layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the convolution. </td></tr>
    <tr><td class="paramname">nbOutputMaps</td><td>The number of output feature maps for the convolution. </td></tr>
    <tr><td class="paramname">kernelSize</td><td>The multi-dimensions of the convolution kernel. </td></tr>
    <tr><td class="paramname">kernelWeights</td><td>The kernel weights for the convolution. </td></tr>
    <tr><td class="paramname">biasWeights</td><td>The optional bias weights for the convolution.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_convolution_layer.html" title="A convolution layer in a network definition. ">IConvolutionLayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>It is an error to specify a wildcard value for the 'C' dimension of the input tensor. </dd>
<dd>
Int32 tensors are not valid input tensors. </dd>
<dd>
Only 2D or 3D convolution is supported.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new convolution layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a80f985a0a5e5e68561ef205bf346fc33"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a80f985a0a5e5e68561ef205bf346fc33">&#9670;&nbsp;</a></span>addDeconvolution()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_deconvolution_layer.html">IDeconvolutionLayer</a>* nvinfer1::INetworkDefinition::addDeconvolution </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbOutputMaps</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a>&#160;</td>
          <td class="paramname"><em>kernelSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>kernelWeights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>biasWeights</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a deconvolution layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">nbOutputMaps</td><td>The number of output feature maps. </td></tr>
    <tr><td class="paramname">kernelSize</td><td>The HW-dimensions of the deconvolution kernel. </td></tr>
    <tr><td class="paramname">kernelWeights</td><td>The kernel weights for the deconvolution. </td></tr>
    <tr><td class="paramname">biasWeights</td><td>The optional bias weights for the deconvolution.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_deconvolution_layer.html" title="A deconvolution layer in a network definition. ">IDeconvolutionLayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>It is an error to specify a wildcard value for the 'C' dimension of the input tensor. </dd>
<dd>
Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new deconvolution layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a64423656a50a3bff760743e371e53dff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a64423656a50a3bff760743e371e53dff">&#9670;&nbsp;</a></span>addDeconvolutionNd()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_deconvolution_layer.html">IDeconvolutionLayer</a>* nvinfer1::INetworkDefinition::addDeconvolutionNd </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbOutputMaps</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims.html">Dims</a>&#160;</td>
          <td class="paramname"><em>kernelSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>kernelWeights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>biasWeights</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a multi-dimension deconvolution layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">nbOutputMaps</td><td>The number of output feature maps. </td></tr>
    <tr><td class="paramname">kernelSize</td><td>The multi-dimensions of the deconvolution kernel. </td></tr>
    <tr><td class="paramname">kernelWeights</td><td>The kernel weights for the deconvolution. </td></tr>
    <tr><td class="paramname">biasWeights</td><td>The optional bias weights for the deconvolution.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_deconvolution_layer.html" title="A deconvolution layer in a network definition. ">IDeconvolutionLayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>It is an error to specify a wildcard value for the 'C' dimension of the input tensor. </dd>
<dd>
Int32 tensors are not valid input tensors. </dd>
<dd>
Only 2D or 3D deconvolution is supported. </dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new deconvolution layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="aa12fda7cb22a7a12f4d58701e9f3988f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa12fda7cb22a7a12f4d58701e9f3988f">&#9670;&nbsp;</a></span>addElementWise()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_element_wise_layer.html">IElementWiseLayer</a>* nvinfer1::INetworkDefinition::addElementWise </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input2</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#a9badc834875b5c57d9556a66e5e20978">ElementWiseOperation</a>&#160;</td>
          <td class="paramname"><em>op</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add an elementwise layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input1</td><td>The first input tensor to the layer. </td></tr>
    <tr><td class="paramname">input2</td><td>The second input tensor to the layer. </td></tr>
    <tr><td class="paramname">op</td><td>The binary operation that the layer applies.</td></tr>
  </table>
  </dd>
</dl>
<p>The input tensors must have the same number of dimensions. For each dimension, their lengths must match, or one of them must be one. In the latter case, the tensor is broadcast along that axis.</p>
<p>The output tensor has the same number of dimensions as the inputs. For each dimension, its length is the maximum of the lengths of the corresponding input dimension.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_element_wise_layer.html" title="A elementwise layer in a network definition. ">IElementWiseLayer</a> </dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>For shape tensors, <a class="el" href="namespacenvinfer1.html#a9badc834875b5c57d9556a66e5e20978a7a47514e619af935eb6e4364494ff40b" title="The first element to the power of the second element. ">ElementWiseOperation::kPOW</a> is not a valid op.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new elementwise layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a411e2cefb9a4307d99fcc442c2a708a8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a411e2cefb9a4307d99fcc442c2a708a8">&#9670;&nbsp;</a></span>addFullyConnected()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_fully_connected_layer.html">IFullyConnectedLayer</a>* nvinfer1::INetworkDefinition::addFullyConnected </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbOutputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>kernelWeights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>biasWeights</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a fully connected layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">nbOutputs</td><td>The number of outputs of the layer. </td></tr>
    <tr><td class="paramname">kernelWeights</td><td>The kernel weights for the convolution. </td></tr>
    <tr><td class="paramname">biasWeights</td><td>The optional bias weights for the convolution.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_fully_connected_layer.html" title="A fully connected layer in a network definition. This layer expects an input tensor of three or more ...">IFullyConnectedLayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>It is an error to specify a wildcard value for the 'C' dimension of the input tensor. </dd>
<dd>
Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new fully connected layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a81ea0b5ce4a6a24e8e4953fd0e0b3216"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a81ea0b5ce4a6a24e8e4953fd0e0b3216">&#9670;&nbsp;</a></span>addGather()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_gather_layer.html">IGatherLayer</a>* nvinfer1::INetworkDefinition::addGather </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>axis</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a gather layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">data</td><td>The tensor to gather values from. </td></tr>
    <tr><td class="paramname">indices</td><td>The tensor to get indices from to populate the output tensor. </td></tr>
    <tr><td class="paramname">axis</td><td>The axis in the data tensor to gather on.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_gather_layer.html">IGatherLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new gather layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a01811cfea946a80324a5538667e2a427"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a01811cfea946a80324a5538667e2a427">&#9670;&nbsp;</a></span>addIdentity()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_identity_layer.html">IIdentityLayer</a>* nvinfer1::INetworkDefinition::addIdentity </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add an identity layer. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_identity_layer.html" title="A layer that represents the identity function. ">IIdentityLayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new identity layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a06a61f560bdf6197afd3368937f62025"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a06a61f560bdf6197afd3368937f62025">&#9670;&nbsp;</a></span>addInput()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a>* nvinfer1::INetworkDefinition::addInput </td>
          <td>(</td>
          <td class="paramtype">const char *&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217">DataType</a>&#160;</td>
          <td class="paramname"><em>type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims.html">Dims</a>&#160;</td>
          <td class="paramname"><em>dimensions</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add an input tensor to the network. </p>
<p>The name of the input tensor is used to find the index into the buffer array for an engine built from the network. The volume of the dimensions must be less than 2^30 elements. For networks with an implicit batch dimension, this volume includes the batch dimension with its length set to the maximum batch size. For networks with all explicit dimensions and with wildcard dimensions, the volume is based on the maxima specified by an IOptimizationProfile.Dimensions are normally positive integers. The exception is that in networks with all explicit dimensions, -1 can be used as a wildcard for a dimension to be specified at runtime. Input tensors with such a wildcard must have a corresponding entry in the IOptimizationProfiles indicating the permitted extrema, and the input dimensions must be set by <a class="el" href="classnvinfer1_1_1_i_execution_context.html#a9f87003474bc387e17782292cc2ea613" title="Set the dynamic dimensions of a binding. ">IExecutionContext::setBindingDimensions</a>. Different <a class="el" href="classnvinfer1_1_1_i_execution_context.html" title="Context for executing inference using an engine, with functionally unsafe features. ">IExecutionContext</a> instances can have different dimensions. Wildcard dimensions are only supported for <a class="el" href="namespacenvinfer1.html#ae1a368a82063d4538abcccbf02f25383a2eb05989f1bbfd98f356f4f3ac2ba2ec" title="Full capability, TensorRT mode without any restrictions. ">EngineCapability::kDEFAULT</a> with <a class="el" href="namespacenvinfer1.html#ac7b09af1461e55d97ba2b2de97d315bca37ae524b76587efa776affdc5cdf2ac1" title="GPU Device. ">DeviceType::kGPU</a>. They are not supported in safety contexts or on the DLA.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name of the tensor. </td></tr>
    <tr><td class="paramname">type</td><td>The type of the data held in the tensor. </td></tr>
    <tr><td class="paramname">dimensions</td><td>The dimensions of the tensor.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section warning"><dt>Warning</dt><dd>It is an error to specify a wildcard value on a dimension that is determined by trained parameters.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_tensor.html" title="A tensor in a network definition. ">ITensor</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new tensor or nullptr if there is an error. </dd></dl>

</div>
</div>
<a id="aa1c8386fd389fd74b0b48121d22abc67"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa1c8386fd389fd74b0b48121d22abc67">&#9670;&nbsp;</a></span>addLRN()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_l_r_n_layer.html">ILRNLayer</a>* nvinfer1::INetworkDefinition::addLRN </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>window</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>alpha</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>beta</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>k</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a LRN layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">window</td><td>The size of the window. </td></tr>
    <tr><td class="paramname">alpha</td><td>The alpha value for the LRN computation. </td></tr>
    <tr><td class="paramname">beta</td><td>The beta value for the LRN computation. </td></tr>
    <tr><td class="paramname">k</td><td>The k value for the LRN computation.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_l_r_n_layer.html" title="A LRN layer in a network definition. ">ILRNLayer</a> </dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new LRN layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a7643943f07380269f3361a0aa5620535"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7643943f07380269f3361a0aa5620535">&#9670;&nbsp;</a></span>addMatrixMultiply() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_matrix_multiply_layer.html">IMatrixMultiplyLayer</a>* nvinfer1::INetworkDefinition::addMatrixMultiply </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#a9ad4a5ef323b8a421ecad9678cd183d2">MatrixOperation</a>&#160;</td>
          <td class="paramname"><em>op0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#a9ad4a5ef323b8a421ecad9678cd183d2">MatrixOperation</a>&#160;</td>
          <td class="paramname"><em>op1</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a MatrixMultiply layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input0</td><td>The first input tensor (commonly A). </td></tr>
    <tr><td class="paramname">op0</td><td>The operation to apply to input0. </td></tr>
    <tr><td class="paramname">input1</td><td>The second input tensor (commonly B). </td></tr>
    <tr><td class="paramname">op1</td><td>The operation to apply to input1.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_matrix_multiply_layer.html" title="Layer that represents a Matrix Multiplication. ">IMatrixMultiplyLayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new matrix multiply layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a6197f3576f446c22c3b60ef60e9e8c62"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6197f3576f446c22c3b60ef60e9e8c62">&#9670;&nbsp;</a></span>addMatrixMultiply() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual TRT_DEPRECATED <a class="el" href="classnvinfer1_1_1_i_matrix_multiply_layer.html">IMatrixMultiplyLayer</a>* nvinfer1::INetworkDefinition::addMatrixMultiply </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>transpose0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input1</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>transpose1</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a MatrixMultiply layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input0</td><td>The first input tensor (commonly A). </td></tr>
    <tr><td class="paramname">transpose0</td><td>If true, op(input0)=transpose(input0), else op(input0)=input0. </td></tr>
    <tr><td class="paramname">input1</td><td>The second input tensor (commonly B). </td></tr>
    <tr><td class="paramname">transpose1</td><td>If true, op(input1)=transpose(input1), else op(input1)=input1.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_matrix_multiply_layer.html" title="Layer that represents a Matrix Multiplication. ">IMatrixMultiplyLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new matrix multiply layer, or nullptr if it could not be created.</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Int32 tensors are not valid input tensors.</dd></dl>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000015">Deprecated:</a></b></dt><dd>This interface is superseded by the overload that replaces bool with MatrixOperation. </dd></dl>

</div>
</div>
<a id="a334d849cb8720a8a66a95fc84487b132"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a334d849cb8720a8a66a95fc84487b132">&#9670;&nbsp;</a></span>addPadding()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_padding_layer.html">IPaddingLayer</a>* nvinfer1::INetworkDefinition::addPadding </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a>&#160;</td>
          <td class="paramname"><em>prePadding</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a>&#160;</td>
          <td class="paramname"><em>postPadding</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a padding layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">prePadding</td><td>The padding to apply to the start of the tensor. </td></tr>
    <tr><td class="paramname">postPadding</td><td>The padding to apply to the end of the tensor.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_padding_layer.html" title="Layer that represents a padding operation. ">IPaddingLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new padding layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a966d57cbe9f10ebf65462d6dd53141b1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a966d57cbe9f10ebf65462d6dd53141b1">&#9670;&nbsp;</a></span>addParametricReLU()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_parametric_re_l_u_layer.html">IParametricReLULayer</a>* nvinfer1::INetworkDefinition::addParametricReLU </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>slope</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a parametric ReLU layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">slope</td><td>The slope tensor to the layer. This tensor should be unidirectionally broadcastable to the input tensor.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_parametric_re_l_u_layer.html" title="Layer that represents a parametric ReLU operation. ">IParametricReLULayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new parametric ReLU layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a87b5de1bc69c2043bce27bca786b5c6b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a87b5de1bc69c2043bce27bca786b5c6b">&#9670;&nbsp;</a></span>addPlugin()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual TRT_DEPRECATED <a class="el" href="classnvinfer1_1_1_i_plugin_layer.html">IPluginLayer</a>* nvinfer1::INetworkDefinition::addPlugin </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *const *&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbInputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_plugin.html">IPlugin</a> &amp;&#160;</td>
          <td class="paramname"><em>plugin</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a plugin layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputs</td><td>The input tensors to the layer. </td></tr>
    <tr><td class="paramname">nbInputs</td><td>The number of input tensors. </td></tr>
    <tr><td class="paramname">plugin</td><td>The layer plugin.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_plugin_layer.html" title="Layer type for plugins. ">IPluginLayer</a></dd></dl>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000010">Deprecated:</a></b></dt><dd><a class="el" href="classnvinfer1_1_1_i_plugin_layer.html" title="Layer type for plugins. ">IPluginLayer</a> is superseded by <a class="el" href="classnvinfer1_1_1_i_plugin_v2.html" title="Plugin class for user-implemented layers. ">IPluginV2</a>. use addPluginV2 instead.</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Plugin inputs do not support wildcard dimensions or explicit batch size networks. </dd>
<dd>
Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>the new plugin layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="ae5f92ffc2baf52db159d1400b549c478"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae5f92ffc2baf52db159d1400b549c478">&#9670;&nbsp;</a></span>addPluginExt()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual TRT_DEPRECATED <a class="el" href="classnvinfer1_1_1_i_plugin_layer.html">IPluginLayer</a>* nvinfer1::INetworkDefinition::addPluginExt </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *const *&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbInputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_plugin_ext.html">IPluginExt</a> &amp;&#160;</td>
          <td class="paramname"><em>plugin</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a plugin layer to the network using an <a class="el" href="classnvinfer1_1_1_i_plugin_ext.html" title="Plugin class for user-implemented layers. ">IPluginExt</a> interface. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputs</td><td>The input tensors to the layer. </td></tr>
    <tr><td class="paramname">nbInputs</td><td>The number of input tensors. </td></tr>
    <tr><td class="paramname">plugin</td><td>The layer plugin.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_plugin_layer.html" title="Layer type for plugins. ">IPluginLayer</a></dd></dl>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000016">Deprecated:</a></b></dt><dd><a class="el" href="classnvinfer1_1_1_i_plugin_layer.html" title="Layer type for plugins. ">IPluginLayer</a> is superseded by <a class="el" href="classnvinfer1_1_1_i_plugin_v2.html" title="Plugin class for user-implemented layers. ">IPluginV2</a>. use addPluginV2 instead.</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Plugin inputs do not support wildcard dimensions or explicit batch size networks. </dd>
<dd>
Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new plugin layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a0c6e2a0b4e1c8a4df1722a24cc7c0473"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0c6e2a0b4e1c8a4df1722a24cc7c0473">&#9670;&nbsp;</a></span>addPluginV2()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_plugin_v2_layer.html">IPluginV2Layer</a>* nvinfer1::INetworkDefinition::addPluginV2 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> *const *&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>nbInputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_plugin_v2.html">IPluginV2</a> &amp;&#160;</td>
          <td class="paramname"><em>plugin</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a plugin layer to the network using the <a class="el" href="classnvinfer1_1_1_i_plugin_v2.html" title="Plugin class for user-implemented layers. ">IPluginV2</a> interface. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputs</td><td>The input tensors to the layer. </td></tr>
    <tr><td class="paramname">nbInputs</td><td>The number of input tensors. </td></tr>
    <tr><td class="paramname">plugin</td><td>The layer plugin.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_plugin_v2_layer.html" title="Layer type for pluginV2. ">IPluginV2Layer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Dimension wildcard are only supported with <a class="el" href="classnvinfer1_1_1_i_plugin_v2_dynamic_ext.html">IPluginV2DynamicExt</a> or <a class="el" href="classnvinfer1_1_1_i_plugin_v2_i_o_ext.html" title="Plugin class for user-implemented layers. ">IPluginV2IOExt</a> plugins. </dd>
<dd>
Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new plugin layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a49459eaa7e1bbff5371365f125c2f0c5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a49459eaa7e1bbff5371365f125c2f0c5">&#9670;&nbsp;</a></span>addPooling()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_pooling_layer.html">IPoolingLayer</a>* nvinfer1::INetworkDefinition::addPooling </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#aaebe16cb048ecf44524d17aaf9eaac14">PoolingType</a>&#160;</td>
          <td class="paramname"><em>type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims_h_w.html">DimsHW</a>&#160;</td>
          <td class="paramname"><em>windowSize</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a pooling layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">type</td><td>The type of pooling to apply. </td></tr>
    <tr><td class="paramname">windowSize</td><td>The size of the pooling window.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_pooling_layer.html" title="A Pooling layer in a network definition. ">IPoolingLayer</a> <a class="el" href="namespacenvinfer1.html#aaebe16cb048ecf44524d17aaf9eaac14" title="The type of pooling to perform in a pooling layer. ">PoolingType</a> </dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new pooling layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a9bf1bc8eab4861a6203c090c8ba3d819"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9bf1bc8eab4861a6203c090c8ba3d819">&#9670;&nbsp;</a></span>addPoolingNd()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_pooling_layer.html">IPoolingLayer</a>* nvinfer1::INetworkDefinition::addPoolingNd </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#aaebe16cb048ecf44524d17aaf9eaac14">PoolingType</a>&#160;</td>
          <td class="paramname"><em>type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims.html">Dims</a>&#160;</td>
          <td class="paramname"><em>windowSize</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a multi-dimension pooling layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">type</td><td>The type of pooling to apply. </td></tr>
    <tr><td class="paramname">windowSize</td><td>The size of the pooling window.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_pooling_layer.html" title="A Pooling layer in a network definition. ">IPoolingLayer</a> <a class="el" href="namespacenvinfer1.html#aaebe16cb048ecf44524d17aaf9eaac14" title="The type of pooling to perform in a pooling layer. ">PoolingType</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Int32 tensors are not valid input tensors. </dd>
<dd>
Only 2D or 3D pooling is supported.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new pooling layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="aea842c9f897201eb855ce164944e9110"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aea842c9f897201eb855ce164944e9110">&#9670;&nbsp;</a></span>addRaggedSoftMax()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_ragged_soft_max_layer.html">IRaggedSoftMaxLayer</a>* nvinfer1::INetworkDefinition::addRaggedSoftMax </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>bounds</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a RaggedSoftMax layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The ZxS input tensor. </td></tr>
    <tr><td class="paramname">bounds</td><td>The Zx1 bounds tensor.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_ragged_soft_max_layer.html" title="A RaggedSoftmax layer in a network definition. ">IRaggedSoftMaxLayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>The bounds tensor cannot have the last dimension be the wildcard character. </dd>
<dd>
Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new RaggedSoftMax layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a41437aa7107e61b82c5f3490984bf011"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a41437aa7107e61b82c5f3490984bf011">&#9670;&nbsp;</a></span>addReduce()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_reduce_layer.html">IReduceLayer</a>* nvinfer1::INetworkDefinition::addReduce </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#a6640220fcbd633240524ba27b5c6c7e7">ReduceOperation</a>&#160;</td>
          <td class="paramname"><em>operation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>reduceAxes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>keepDimensions</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a reduce layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">operation</td><td>The reduction operation to perform. </td></tr>
    <tr><td class="paramname">reduceAxes</td><td>The reduction dimensions. The bit in position i of bitmask reduceAxes corresponds to explicit dimension i if result. E.g., the least significant bit corresponds to the first explicit dimension and the next to least significant bit corresponds to the second explicit dimension.</td></tr>
    <tr><td class="paramname">keepDimensions</td><td>The boolean that specifies whether or not to keep the reduced dimensions in the output of the layer.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_reduce_layer.html" title="Layer that represents a reduction operator. ">IReduceLayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>If input is a shape tensor, ReduceOperation::kAVG is unsupported.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new reduce layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a12b4eb2416951d1f575d3fc263395bb9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a12b4eb2416951d1f575d3fc263395bb9">&#9670;&nbsp;</a></span>addResize()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_resize_layer.html">IResizeLayer</a>* nvinfer1::INetworkDefinition::addResize </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a resize layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_resize_layer.html" title="A resize layer in a network definition. ">IResizeLayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new resize layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a7c01c498d5adf7d48077827cc9c09021"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7c01c498d5adf7d48077827cc9c09021">&#9670;&nbsp;</a></span>addRNN()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual TRT_DEPRECATED <a class="el" href="classnvinfer1_1_1_i_r_n_n_layer.html">IRNNLayer</a>* nvinfer1::INetworkDefinition::addRNN </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>layerCount</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::size_t&#160;</td>
          <td class="paramname"><em>hiddenSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>maxSeqLen</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#ace7b656a1c0537ea0edd17cf61121200">RNNOperation</a>&#160;</td>
          <td class="paramname"><em>op</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#a1c31bdeeb9aa6bcffeb71cc5a3f126fd">RNNInputMode</a>&#160;</td>
          <td class="paramname"><em>mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#abda12e12ae04a971df63667dc4df99d8">RNNDirection</a>&#160;</td>
          <td class="paramname"><em>dir</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>weights</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>bias</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add an <code>layerCount</code> deep RNN layer to the network with a sequence length of <code>maxSeqLen</code> and <code>hiddenSize</code> internal state per layer. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">inputs</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">layerCount</td><td>The number of layers in the RNN. </td></tr>
    <tr><td class="paramname">hiddenSize</td><td>The size of the internal hidden state for each layer. </td></tr>
    <tr><td class="paramname">maxSeqLen</td><td>The maximum length of the time sequence. </td></tr>
    <tr><td class="paramname">op</td><td>The type of RNN to execute. </td></tr>
    <tr><td class="paramname">mode</td><td>The input mode for the RNN. </td></tr>
    <tr><td class="paramname">dir</td><td>The direction to run the RNN. </td></tr>
    <tr><td class="paramname">weights</td><td>The weights for the weight matrix parameters of the RNN. </td></tr>
    <tr><td class="paramname">bias</td><td>The weights for the bias vectors parameters of the RNN.</td></tr>
  </table>
  </dd>
</dl>
<p>The input tensors must be of the type <a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217a2963c06d855a6b49f4b1abe2010e90b5" title="FP32 format. ">DataType::kFLOAT</a> or <a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217a67c1d9d7d355bd0be230f76e802c470a" title="FP16 format. ">DataType::kHALF</a>.</p>
<p>See <a class="el" href="classnvinfer1_1_1_i_r_n_n_layer.html#a9333d560e68d49cbf60ba34d8872abf1" title="Set the weight parameters for the RNN. ">IRNNLayer::setWeights()</a> and <a class="el" href="classnvinfer1_1_1_i_r_n_n_layer.html#ae1a1d9599294c990d281a80ca684f1f0" title="Set the bias parameters for the RNN. ">IRNNLayer::setBias()</a> for details on the required input format for <code>weights</code> and <code>bias</code>.</p>
<p>The layout for the <code>input</code> tensor should be <code>{1, S_max, N, E}</code>, where:</p><ul>
<li><code>S_max</code> is the maximum allowed sequence length (number of RNN iterations)</li>
<li><code>N</code> is the batch size</li>
<li><code>E</code> specifies the embedding length (unless <a class="el" href="namespacenvinfer1.html#a1c31bdeeb9aa6bcffeb71cc5a3f126fda903acc6373488fa3259402ba97e8b4fb" title="No operation is performed on the first recurrent layer. ">kSKIP</a> is set, in which case it should match getHiddenSize()).</li>
</ul>
<p>The first output tensor is the output of the final RNN layer across all timesteps, with dimensions <code>{S_max, N, H}</code>:</p>
<ul>
<li><code>S_max</code> is the maximum allowed sequence length (number of RNN iterations)</li>
<li><code>N</code> is the batch size</li>
<li><code>H</code> is an output hidden state (equal to getHiddenSize() or 2x getHiddenSize())</li>
</ul>
<p>The second tensor is the final hidden state of the RNN across all layers, and if the RNN is an LSTM (i.e. getOperation() is <a class="el" href="namespacenvinfer1.html#ace7b656a1c0537ea0edd17cf61121200a2046aea763d568b2d5921641f57ec960" title="Four-gate LSTM network w/o peephole connections. ">kLSTM</a>), then the third tensor is the final cell state of the RNN across all layers. Both the second and third output tensors have dimensions <code>{L, N, H}</code>:</p>
<ul>
<li><code>L</code> is equal to getLayerCount() if getDirection is <a class="el" href="namespacenvinfer1.html#abda12e12ae04a971df63667dc4df99d8a8599511603177311d4fc15c066f33461" title="Network iterations from first input to last input. ">kUNIDIRECTION</a>, and 2*getLayerCount() if getDirection is <a class="el" href="namespacenvinfer1.html#abda12e12ae04a971df63667dc4df99d8a80c42616519e496e81b782101cd595af" title="Network iterates from first to last and vice versa and outputs concatenated. ">kBIDIRECTION</a>. In the bi-directional case, layer <code>l</code>'s final forward hidden state is stored in <code>L = 2*l</code>, and final backward hidden state is stored in <code>L = 2*l + 1</code>.</li>
<li><code>N</code> is the batch size</li>
<li><code>H</code> is getHiddenSize().</li>
</ul>
<p>Note that in bidirectional RNNs, the full "hidden state" for a layer <code>l</code> is the concatenation of its forward hidden state and its backward hidden state, and its size is 2*H.</p>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000009">Deprecated:</a></b></dt><dd><a class="el" href="classnvinfer1_1_1_i_r_n_n_layer.html" title="A RNN layer in a network definition. ">IRNNLayer</a> is superseded by <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html" title="An RNN layer in a network definition, version 2. ">IRNNv2Layer</a>. Use <a class="el" href="classnvinfer1_1_1_i_network_definition.html#a6cd3869f7406f73261857987be1b18a9" title="Add an layerCount deep RNN layer to the network with hiddenSize internal states that can take a batch...">addRNNv2()</a> instead.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_r_n_n_layer.html" title="A RNN layer in a network definition. ">IRNNLayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>RNN inputs do not support wildcard dimensions or explicit batch size networks. </dd>
<dd>
Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new RNN layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a6cd3869f7406f73261857987be1b18a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6cd3869f7406f73261857987be1b18a9">&#9670;&nbsp;</a></span>addRNNv2()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html">IRNNv2Layer</a>* nvinfer1::INetworkDefinition::addRNNv2 </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>layerCount</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>hiddenSize</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>maxSeqLen</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#ace7b656a1c0537ea0edd17cf61121200">RNNOperation</a>&#160;</td>
          <td class="paramname"><em>op</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add an <code>layerCount</code> deep RNN layer to the network with <code>hiddenSize</code> internal states that can take a batch with fixed or variable sequence lengths. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer (see below). </td></tr>
    <tr><td class="paramname">layerCount</td><td>The number of layers in the RNN. </td></tr>
    <tr><td class="paramname">hiddenSize</td><td>Size of the internal hidden state for each layer. </td></tr>
    <tr><td class="paramname">maxSeqLen</td><td>Maximum sequence length for the input. </td></tr>
    <tr><td class="paramname">op</td><td>The type of RNN to execute.</td></tr>
  </table>
  </dd>
</dl>
<p>By default, the layer is configured with <a class="el" href="namespacenvinfer1.html#abda12e12ae04a971df63667dc4df99d8a8599511603177311d4fc15c066f33461" title="Network iterations from first input to last input. ">RNNDirection::kUNIDIRECTION</a> and <a class="el" href="namespacenvinfer1.html#a1c31bdeeb9aa6bcffeb71cc5a3f126fdafd0bda8f85b35011bdcde415691fc36f" title="Perform the normal matrix multiplication in the first recurrent layer. ">RNNInputMode::kLINEAR</a>. To change these settings, use <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html#a9b941de0998d728accad69c61198fde7" title="Set the direction of the RNN layer. ">IRNNv2Layer::setDirection()</a> and <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html#a0a7faa3f0e695ac6431bcccc12851954" title="Set the input mode of the RNN layer. ">IRNNv2Layer::setInputMode()</a>.</p>
<p>Weights and biases for the added layer should be set using <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html#ac5e9205e8cb648b75bc918e92f55a2a6" title="Set the weight parameters for an individual gate in the RNN. ">IRNNv2Layer::setWeightsForGate()</a> and <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html#a278902915200ab6c6b08c8f9671d6337" title="Set the bias parameters for an individual gate in the RNN. ">IRNNv2Layer::setBiasForGate()</a> prior to building an engine using this network.</p>
<p>The input tensors must be of the type <a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217a2963c06d855a6b49f4b1abe2010e90b5" title="FP32 format. ">DataType::kFLOAT</a> or <a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217a67c1d9d7d355bd0be230f76e802c470a" title="FP16 format. ">DataType::kHALF</a>. The layout of the weights is row major and must be the same datatype as the input tensor. <code>weights</code> contain 8 matrices and <code>bias</code> contains 8 vectors.</p>
<p>See <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html#ac5e9205e8cb648b75bc918e92f55a2a6" title="Set the weight parameters for an individual gate in the RNN. ">IRNNv2Layer::setWeightsForGate()</a> and <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html#a278902915200ab6c6b08c8f9671d6337" title="Set the bias parameters for an individual gate in the RNN. ">IRNNv2Layer::setBiasForGate()</a> for details on the required input format for <code>weights</code> and <code>bias</code>.</p>
<p>The <code>input</code> <a class="el" href="classnvinfer1_1_1_i_tensor.html" title="A tensor in a network definition. ">ITensor</a> should contain zero or more index dimensions <code>{N1, ..., Np}</code>, followed by two dimensions, defined as follows:</p><ul>
<li><code>S_max</code> is the maximum allowed sequence length (number of RNN iterations)</li>
<li><code>E</code> specifies the embedding length (unless <a class="el" href="namespacenvinfer1.html#a1c31bdeeb9aa6bcffeb71cc5a3f126fda903acc6373488fa3259402ba97e8b4fb" title="No operation is performed on the first recurrent layer. ">kSKIP</a> is set, in which case it should match getHiddenSize()).</li>
</ul>
<p>By default, all sequences in the input are assumed to be size <code>maxSeqLen</code>. To provide explicit sequence lengths for each input sequence in the batch, use <a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html#a8a29104927bc766971561eb8fbcbb3e8" title="Specify individual sequence lengths in the batch with the ITensor pointed to by seqLengths. ">IRNNv2Layer::setSequenceLengths()</a>.</p>
<p>The RNN layer outputs up to three tensors.</p>
<p>The first output tensor is the output of the final RNN layer across all timesteps, with dimensions <code>{N1, ..., Np, S_max, H}</code>:</p>
<ul>
<li><code>N1..Np</code> are the index dimensions specified by the input tensor</li>
<li><code>S_max</code> is the maximum allowed sequence length (number of RNN iterations)</li>
<li><code>H</code> is an output hidden state (equal to getHiddenSize() or 2x getHiddenSize())</li>
</ul>
<p>The second tensor is the final hidden state of the RNN across all layers, and if the RNN is an LSTM (i.e. getOperation() is <a class="el" href="namespacenvinfer1.html#ace7b656a1c0537ea0edd17cf61121200a2046aea763d568b2d5921641f57ec960" title="Four-gate LSTM network w/o peephole connections. ">kLSTM</a>), then the third tensor is the final cell state of the RNN across all layers. Both the second and third output tensors have dimensions <code>{N1, ..., Np, L, H}</code>:</p>
<ul>
<li><code>N1..Np</code> are the index dimensions specified by the input tensor</li>
<li><code>L</code> is the number of layers in the RNN, equal to getLayerCount() if getDirection is <a class="el" href="namespacenvinfer1.html#abda12e12ae04a971df63667dc4df99d8a8599511603177311d4fc15c066f33461" title="Network iterations from first input to last input. ">kUNIDIRECTION</a>, and 2x getLayerCount() if getDirection is <a class="el" href="namespacenvinfer1.html#abda12e12ae04a971df63667dc4df99d8a80c42616519e496e81b782101cd595af" title="Network iterates from first to last and vice versa and outputs concatenated. ">kBIDIRECTION</a>. In the bi-directional case, layer <code>l</code>'s final forward hidden state is stored in <code>L = 2*l</code>, and final backward hidden state is stored in <code>L= 2*l + 1</code>.</li>
<li><code>H</code> is the hidden state for each layer, equal to getHiddenSize().</li>
</ul>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_r_n_nv2_layer.html" title="An RNN layer in a network definition, version 2. ">IRNNv2Layer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>RNN inputs do not support wildcard dimensions or explicit batch size networks. </dd>
<dd>
Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new RNN layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a37cf24c7c620aa661de167f302559289"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a37cf24c7c620aa661de167f302559289">&#9670;&nbsp;</a></span>addScale()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_scale_layer.html">IScaleLayer</a>* nvinfer1::INetworkDefinition::addScale </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#aa718ced5536f804059d1c9ab7b9489d0">ScaleMode</a>&#160;</td>
          <td class="paramname"><em>mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>power</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a Scale layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. This tensor is required to have a minimum of 3 dimensions. </td></tr>
    <tr><td class="paramname">mode</td><td>The scaling mode. </td></tr>
    <tr><td class="paramname">shift</td><td>The shift value. </td></tr>
    <tr><td class="paramname">scale</td><td>The scale value. </td></tr>
    <tr><td class="paramname">power</td><td>The power value.</td></tr>
  </table>
  </dd>
</dl>
<p>If the weights are available, then the size of weights are dependent on the ScaleMode. For <a class="el" href="namespacenvinfer1.html#aa718ced5536f804059d1c9ab7b9489d0a1f65127b6291c007dd952d4ebc39b1bf" title="Identical coefficients across all elements of the tensor. ">kUNIFORM</a>, the number of weights is equal to 1. For <a class="el" href="namespacenvinfer1.html#aa718ced5536f804059d1c9ab7b9489d0afbf2bd146f6f86d9ab02397d16eca973" title="Per-channel coefficients. ">kCHANNEL</a>, the number of weights is equal to the channel dimension. For <a class="el" href="namespacenvinfer1.html#a6fd444d95c9f8dcf9d87771b6d3c863dabf7aa33cd17f025808e60f6e1690fd11" title="Elementwise layer. ">kELEMENTWISE</a>, the number of weights is equal to the volume of the input.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_scale_layer.html" title="A Scale layer in a network definition. ">IScaleLayer</a> </dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new Scale layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="aa2af68900fe0f5635b63212eaa3c4324"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa2af68900fe0f5635b63212eaa3c4324">&#9670;&nbsp;</a></span>addScaleNd()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_scale_layer.html">IScaleLayer</a>* nvinfer1::INetworkDefinition::addScaleNd </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#aa718ced5536f804059d1c9ab7b9489d0">ScaleMode</a>&#160;</td>
          <td class="paramname"><em>mode</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>scale</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_weights.html">Weights</a>&#160;</td>
          <td class="paramname"><em>power</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>channelAxis</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a multi-dimension scale layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">mode</td><td>The scaling mode. </td></tr>
    <tr><td class="paramname">shift</td><td>The shift value. </td></tr>
    <tr><td class="paramname">scale</td><td>The scale value. </td></tr>
    <tr><td class="paramname">power</td><td>The power value. </td></tr>
    <tr><td class="paramname">channelAxis</td><td>The channel axis.</td></tr>
  </table>
  </dd>
</dl>
<p>If the weights are available, then the size of weights are dependent on the ScaleMode. For <a class="el" href="namespacenvinfer1.html#aa718ced5536f804059d1c9ab7b9489d0a1f65127b6291c007dd952d4ebc39b1bf" title="Identical coefficients across all elements of the tensor. ">kUNIFORM</a>, the number of weights is equal to 1. For <a class="el" href="namespacenvinfer1.html#aa718ced5536f804059d1c9ab7b9489d0afbf2bd146f6f86d9ab02397d16eca973" title="Per-channel coefficients. ">kCHANNEL</a>, the number of weights is equal to the channel dimension. For <a class="el" href="namespacenvinfer1.html#a6fd444d95c9f8dcf9d87771b6d3c863dabf7aa33cd17f025808e60f6e1690fd11" title="Elementwise layer. ">kELEMENTWISE</a>, the number of weights is equal to the volume of the input.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_scale_layer.html" title="A Scale layer in a network definition. ">IScaleLayer</a> </dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Int32 tensors are not valid input tensors. </dd>
<dd>
Only 2D or 3D scale is supported.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new Scale layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="ab4eccbfe457683551e68106b827b1f9d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab4eccbfe457683551e68106b827b1f9d">&#9670;&nbsp;</a></span>addShape()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_shape_layer.html">IShapeLayer</a>* nvinfer1::INetworkDefinition::addShape </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a shape layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_shape_layer.html" title="Layer type for getting shape of a tensor. ">IShapeLayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>addShape is only supported when hasImplicitBatchDimensions is false.</dd>
<dd>
input to addShape cannot contain wildcard dimension values.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new shape layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a2628a97544b7802076246069321e2bf9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2628a97544b7802076246069321e2bf9">&#9670;&nbsp;</a></span>addShuffle()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_shuffle_layer.html">IShuffleLayer</a>* nvinfer1::INetworkDefinition::addShuffle </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a shuffle layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_shuffle_layer.html" title="Layer type for shuffling data. ">IShuffleLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new shuffle layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="ab3d64683b10afdbc944075da818fb086"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab3d64683b10afdbc944075da818fb086">&#9670;&nbsp;</a></span>addSlice()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_slice_layer.html">ISliceLayer</a>* nvinfer1::INetworkDefinition::addSlice </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims.html">Dims</a>&#160;</td>
          <td class="paramname"><em>start</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims.html">Dims</a>&#160;</td>
          <td class="paramname"><em>size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_dims.html">Dims</a>&#160;</td>
          <td class="paramname"><em>stride</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a slice layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">start</td><td>The start offset </td></tr>
    <tr><td class="paramname">size</td><td>The output dimension </td></tr>
    <tr><td class="paramname">stride</td><td>The slicing stride</td></tr>
  </table>
  </dd>
</dl>
<p>Positive, negative, zero stride values, and combinations of them in different dimensions are allowed.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_slice_layer.html" title="Slices an input tensor into an output tensor based on the offset and strides. ">ISliceLayer</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new slice layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a595af67528bf0664afa9815114933320"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a595af67528bf0664afa9815114933320">&#9670;&nbsp;</a></span>addSoftMax()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_soft_max_layer.html">ISoftMaxLayer</a>* nvinfer1::INetworkDefinition::addSoftMax </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a SoftMax layer to the network. </p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_soft_max_layer.html" title="A Softmax layer in a network definition. ">ISoftMaxLayer</a> </dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new SoftMax layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a384a409318bf416be3aa4442f2b0ce76"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a384a409318bf416be3aa4442f2b0ce76">&#9670;&nbsp;</a></span>addTopK()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_top_k_layer.html">ITopKLayer</a>* nvinfer1::INetworkDefinition::addTopK </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#a1323342950a2702ba66e29c64404a7f3">TopKOperation</a>&#160;</td>
          <td class="paramname"><em>op</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>k</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>reduceAxes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a TopK layer to the network. </p>
<p>The TopK layer has two outputs of the same dimensions. The first contains data values, the second contains index positions for the values. Output values are sorted, largest first for operation kMAX and smallest first for operation kMIN.</p>
<p>Currently only values of K up to 1024 are supported.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer.</td></tr>
    <tr><td class="paramname">op</td><td>Operation to perform.</td></tr>
    <tr><td class="paramname">k</td><td>Number of elements to keep.</td></tr>
    <tr><td class="paramname">reduceAxes</td><td>The reduction dimensions. The bit in position i of bitmask reduceAxes corresponds to explicit dimension i of the result. E.g., the least significant bit corresponds to the first explicit dimension and the next to least significant bit corresponds to the second explicit dimension.</td></tr>
  </table>
  </dd>
</dl>
<p>Currently reduceAxes must specify exactly one dimension, and it must be one of the last four dimensions.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_top_k_layer.html" title="Layer that represents a TopK reduction. ">ITopKLayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new TopK layer, or nullptr if it could not be created. </dd></dl>

</div>
</div>
<a id="a4b85bd3f05c234fcc1118f827d7c0720"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4b85bd3f05c234fcc1118f827d7c0720">&#9670;&nbsp;</a></span>addUnary()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_unary_layer.html">IUnaryLayer</a>* nvinfer1::INetworkDefinition::addUnary </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>input</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacenvinfer1.html#aeaeaae08a730508ead278d52b8517a09">UnaryOperation</a>&#160;</td>
          <td class="paramname"><em>operation</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Add a unary layer to the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input</td><td>The input tensor to the layer. </td></tr>
    <tr><td class="paramname">operation</td><td>The operation to apply.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_unary_layer.html" title="Layer that represents an unary operation. ">IUnaryLayer</a></dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Int32 tensors are not valid input tensors.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The new unary layer, or nullptr if it could not be created </dd></dl>

</div>
</div>
<a id="adb198d5371d6ed8488708f319232f5ba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adb198d5371d6ed8488708f319232f5ba">&#9670;&nbsp;</a></span>getConvolutionOutputDimensionsFormula()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual TRT_DEPRECATED <a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a>&amp; nvinfer1::INetworkDefinition::getConvolutionOutputDimensionsFormula </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the convolution output dimensions formula. </p>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000012">Deprecated:</a></b></dt><dd>This method does not currently work reliably and will be removed in a future release.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>The formula from computing the convolution output dimensions.</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Custom output dimensions formulas are not supported with wildcard dimensions.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html" title="Application-implemented interface to compute layer output sizes. ">IOutputDimensionsFormula</a> <a class="el" href="classnvinfer1_1_1_i_network_definition.html#ab83e073d7230aefc36f1ce2168da24c3" title="Set the convolution output dimensions formula. ">setConvolutionOutputDimensionsFormula()</a> </dd></dl>

</div>
</div>
<a id="a61198efbae4b7573052fc6be4b1a59ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a61198efbae4b7573052fc6be4b1a59ed">&#9670;&nbsp;</a></span>getDeconvolutionOutputDimensionsFormula()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual TRT_DEPRECATED <a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a>&amp; nvinfer1::INetworkDefinition::getDeconvolutionOutputDimensionsFormula </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the deconvolution output dimensions formula. </p>
<dl class="section return"><dt>Returns</dt><dd>The formula from computing the deconvolution output dimensions.</dd></dl>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000014">Deprecated:</a></b></dt><dd>This method does not currently work reliably and will be removed in a future release.</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Custom output dimensions formulas are not supported with wildcard dimensions.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html" title="Application-implemented interface to compute layer output sizes. ">IOutputDimensionsFormula</a> <a class="el" href="classnvinfer1_1_1_i_network_definition.html#a34b77e89e6fca477d4ad24b8461b9633" title="Set the deconvolution output dimensions formula. ">setDeconvolutionOutputDimensionsFormula()</a> </dd></dl>

</div>
</div>
<a id="aaecdd8775e0ce4643112932f721f93c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aaecdd8775e0ce4643112932f721f93c1">&#9670;&nbsp;</a></span>getInput()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a>* nvinfer1::INetworkDefinition::getInput </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the input tensor specified by the given index. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">index</td><td>The index of the input tensor.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The input tensor, or nullptr if the index is out of range.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_network_definition.html#ac7a0538c92b9850b3ecd939609759cdd" title="Get the number of inputs in the network. ">getNbInputs()</a> </dd></dl>

</div>
</div>
<a id="a4a81749aaa08e93ca4ae1dbb1739c7bd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4a81749aaa08e93ca4ae1dbb1739c7bd">&#9670;&nbsp;</a></span>getLayer()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_layer.html">ILayer</a>* nvinfer1::INetworkDefinition::getLayer </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the layer specified by the given index. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">index</td><td>The index of the layer.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The layer, or nullptr if the index is out of range.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a191a7724fc0c03a3b6f5fd8782dcd30e" title="Get the number of layers in the network. ">getNbLayers()</a> </dd></dl>

</div>
</div>
<a id="ae6b53187d680c53e89c19cd39bc66beb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae6b53187d680c53e89c19cd39bc66beb">&#9670;&nbsp;</a></span>getName()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual const char* nvinfer1::INetworkDefinition::getName </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the name associated with the network. </p>
<p>The memory pointed to by <a class="el" href="classnvinfer1_1_1_i_network_definition.html#ae6b53187d680c53e89c19cd39bc66beb" title="Returns the name associated with the network. ">getName()</a> is owned by the <a class="el" href="classnvinfer1_1_1_i_network_definition.html" title="A network definition for input to the builder. ">INetworkDefinition</a> object.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a2d3ffd5af77299ca45ab7a286e21eaef" title="Sets the name of the network. ">INetworkDefinition::setName()</a></dd></dl>
<dl class="section return"><dt>Returns</dt><dd>A zero delimited C-style string representing the name of the network. </dd></dl>

</div>
</div>
<a id="ac7a0538c92b9850b3ecd939609759cdd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac7a0538c92b9850b3ecd939609759cdd">&#9670;&nbsp;</a></span>getNbInputs()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int nvinfer1::INetworkDefinition::getNbInputs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the number of inputs in the network. </p>
<dl class="section return"><dt>Returns</dt><dd>The number of inputs in the network.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aaecdd8775e0ce4643112932f721f93c1" title="Get the input tensor specified by the given index. ">getInput()</a> </dd></dl>

</div>
</div>
<a id="a191a7724fc0c03a3b6f5fd8782dcd30e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a191a7724fc0c03a3b6f5fd8782dcd30e">&#9670;&nbsp;</a></span>getNbLayers()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int nvinfer1::INetworkDefinition::getNbLayers </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the number of layers in the network. </p>
<dl class="section return"><dt>Returns</dt><dd>The number of layers in the network.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a4a81749aaa08e93ca4ae1dbb1739c7bd" title="Get the layer specified by the given index. ">getLayer()</a> </dd></dl>

</div>
</div>
<a id="a1eb3e1df9e652363d7ab4e3796794bb2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1eb3e1df9e652363d7ab4e3796794bb2">&#9670;&nbsp;</a></span>getNbOutputs()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int nvinfer1::INetworkDefinition::getNbOutputs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the number of outputs in the network. </p>
<p>The outputs include those marked by markOutput or markOutputForShapes.</p>
<dl class="section return"><dt>Returns</dt><dd>The number of outputs in the network.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a6eb45e378bf2b2097da64e3886010bd0" title="Get the output tensor specified by the given index. ">getOutput()</a> </dd></dl>

</div>
</div>
<a id="a6eb45e378bf2b2097da64e3886010bd0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6eb45e378bf2b2097da64e3886010bd0">&#9670;&nbsp;</a></span>getOutput()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a>* nvinfer1::INetworkDefinition::getOutput </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the output tensor specified by the given index. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">index</td><td>The index of the output tensor.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The output tensor, or nullptr if the index is out of range.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a1eb3e1df9e652363d7ab4e3796794bb2" title="Get the number of outputs in the network. ">getNbOutputs()</a> </dd></dl>

</div>
</div>
<a id="aa0c2ec41c0a88e6f69bad7fa910baea6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa0c2ec41c0a88e6f69bad7fa910baea6">&#9670;&nbsp;</a></span>getPoolingOutputDimensionsFormula()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual TRT_DEPRECATED <a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a>&amp; nvinfer1::INetworkDefinition::getPoolingOutputDimensionsFormula </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the pooling output dimensions formula. </p>
<dl class="section return"><dt>Returns</dt><dd>The formula from computing the pooling output dimensions.</dd></dl>
<dl class="section warning"><dt>Warning</dt><dd>Custom output dimensions formulas are not supported with wildcard dimensions.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html" title="Application-implemented interface to compute layer output sizes. ">IOutputDimensionsFormula</a> <a class="el" href="classnvinfer1_1_1_i_network_definition.html#a402ad2fbbf572f592077c6c0ea12a51f" title="Set the pooling output dimensions formula. ">setPoolingOutputDimensionsFormula()</a> </dd></dl>

</div>
</div>
<a id="a46f05bc0dcd87790b406c3301ccc1e7d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a46f05bc0dcd87790b406c3301ccc1e7d">&#9670;&nbsp;</a></span>hasExplicitPrecision()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool nvinfer1::INetworkDefinition::hasExplicitPrecision </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>True if network is an explicit precision network. </p>
<p><a class="el" href="classnvinfer1_1_1_i_network_definition.html#a46f05bc0dcd87790b406c3301ccc1e7d" title="True if network is an explicit precision network. ">hasExplicitPrecision()</a> is true if and only if this <a class="el" href="classnvinfer1_1_1_i_network_definition.html" title="A network definition for input to the builder. ">INetworkDefinition</a> was created with createNetworkV2() with <a class="el" href="namespacenvinfer1.html#a2c2e49e471b8f25230885f7ab881264bac1d5bcbbbe1176cede9cacdf35375e7e" title="Mark the network to be an explicit precision network. ">NetworkDefinitionCreationFlag::kEXPLICIT_PRECISION</a> set.</p>
<dl class="section see"><dt>See also</dt><dd>createNetworkV2</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>True if network has explicit precision, false otherwise. </dd></dl>

</div>
</div>
<a id="aa4373cda43b868d9e4c8f3d862f4d7aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa4373cda43b868d9e4c8f3d862f4d7aa">&#9670;&nbsp;</a></span>hasImplicitBatchDimension()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool nvinfer1::INetworkDefinition::hasImplicitBatchDimension </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>True if tensors have implicit batch dimension. </p>
<dl class="section return"><dt>Returns</dt><dd>True if tensors have implicit batch dimension, false otherwise.</dd></dl>
<p>This is a network-wide property. Either all tensors in the network have an implicit batch dimension or none of them do.</p>
<p><a class="el" href="classnvinfer1_1_1_i_network_definition.html#aa4373cda43b868d9e4c8f3d862f4d7aa" title="True if tensors have implicit batch dimension. ">hasImplicitBatchDimension()</a> is true if and only if this <a class="el" href="classnvinfer1_1_1_i_network_definition.html" title="A network definition for input to the builder. ">INetworkDefinition</a> was created with createNetwork() or createNetworkV2() without <a class="el" href="namespacenvinfer1.html#a2c2e49e471b8f25230885f7ab881264ba85b8fdd336af67a4aa147b3430064945" title="Mark the network to be an explicit batch network. ">NetworkDefinitionCreationFlag::kEXPLICIT_BATCH</a> flag.</p>
<dl class="section see"><dt>See also</dt><dd>createNetworkV2 </dd></dl>

</div>
</div>
<a id="a5d2cdec24bc4a1507fc80f100e18cfe9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5d2cdec24bc4a1507fc80f100e18cfe9">&#9670;&nbsp;</a></span>markOutput()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void nvinfer1::INetworkDefinition::markOutput </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>tensor</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Mark a tensor as a network output. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to mark as an output tensor.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section warning"><dt>Warning</dt><dd>It is an error to mark a network input as an output. </dd></dl>

</div>
</div>
<a id="a1f0fff6e9c2469e31ac3be82dd3f0f28"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1f0fff6e9c2469e31ac3be82dd3f0f28">&#9670;&nbsp;</a></span>markOutputForShapes()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool nvinfer1::INetworkDefinition::markOutputForShapes </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>tensor</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Enable tensor's value to be computed by <a class="el" href="classnvinfer1_1_1_i_execution_context.html#a3afb239c59299f5e88a617781d294d44" title="Get values of an input tensor required for shape calculations or an output tensor produced by shape c...">IExecutionContext::getShapeBinding</a>. </p>
<dl class="section return"><dt>Returns</dt><dd>True if successful, false if tensor is already marked as an output.</dd></dl>
<p>The tensor must be of type <a class="el" href="namespacenvinfer1.html#afec8200293dc7ed40aca48a763592217abd073fcbb15020b25a70e2cd95f9f4a9" title="INT32 format. ">DataType::kINT32</a> and have no more than one dimension.</p>
<dl class="section warning"><dt>Warning</dt><dd>The tensor must have dimensions that can be determined to be constants at build time.</dd>
<dd>
It is an error to mark a network input as a shape output.</dd></dl>
<dl class="section see"><dt>See also</dt><dd>isShapeBinding(), getShapeBinding() </dd></dl>

</div>
</div>
<a id="a17e88f382119792187af786c3cc83770"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a17e88f382119792187af786c3cc83770">&#9670;&nbsp;</a></span>removeTensor()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void nvinfer1::INetworkDefinition::removeTensor </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>tensor</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>remove a tensor from the network definition. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>the tensor to remove</td></tr>
  </table>
  </dd>
</dl>
<p>It is illegal to remove a tensor that is the input or output of a layer. if this method is called with such a tensor, a warning will be emitted on the log and the call will be ignored. Its intended use is to remove detached tensors after e.g. concatenating two networks with Layer::setInput(). </p>

</div>
</div>
<a id="ab83e073d7230aefc36f1ce2168da24c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab83e073d7230aefc36f1ce2168da24c3">&#9670;&nbsp;</a></span>setConvolutionOutputDimensionsFormula()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual TRT_DEPRECATED void nvinfer1::INetworkDefinition::setConvolutionOutputDimensionsFormula </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> *&#160;</td>
          <td class="paramname"><em>formula</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Set the convolution output dimensions formula. </p>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000011">Deprecated:</a></b></dt><dd>This method does not currently work reliably and will be removed in a future release.</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">formula</td><td>The formula from computing the convolution output dimensions. If null is passed, the default formula is used.</td></tr>
  </table>
  </dd>
</dl>
<p>The default formula in each dimension is (inputDim + padding * 2 - kernelSize) / stride + 1.</p>
<dl class="section warning"><dt>Warning</dt><dd>Custom output dimensions formulas are not supported with wildcard dimensions.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html" title="Application-implemented interface to compute layer output sizes. ">IOutputDimensionsFormula</a> <a class="el" href="classnvinfer1_1_1_i_network_definition.html#adb198d5371d6ed8488708f319232f5ba" title="Get the convolution output dimensions formula. ">getConvolutionOutputDimensionsFormula()</a> </dd></dl>

</div>
</div>
<a id="a34b77e89e6fca477d4ad24b8461b9633"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a34b77e89e6fca477d4ad24b8461b9633">&#9670;&nbsp;</a></span>setDeconvolutionOutputDimensionsFormula()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual TRT_DEPRECATED void nvinfer1::INetworkDefinition::setDeconvolutionOutputDimensionsFormula </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> *&#160;</td>
          <td class="paramname"><em>formula</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Set the deconvolution output dimensions formula. </p>
<dl class="deprecated"><dt><b><a class="el" href="deprecated.html#_deprecated000013">Deprecated:</a></b></dt><dd>This method does not currently work reliably and will be removed in a future release.</dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">formula</td><td>The formula from computing the deconvolution output dimensions. If null is passed, the default! formula is used.</td></tr>
  </table>
  </dd>
</dl>
<p>The default formula in each dimension is (inputDim - 1) * stride + kernelSize - 2 * padding.</p>
<dl class="section warning"><dt>Warning</dt><dd>Custom output dimensions formulas are not supported with wildcard dimensions.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html" title="Application-implemented interface to compute layer output sizes. ">IOutputDimensionsFormula</a> getDevonvolutionOutputDimensionsFormula() </dd></dl>

</div>
</div>
<a id="a2d3ffd5af77299ca45ab7a286e21eaef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2d3ffd5af77299ca45ab7a286e21eaef">&#9670;&nbsp;</a></span>setName()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void nvinfer1::INetworkDefinition::setName </td>
          <td>(</td>
          <td class="paramtype">const char *&#160;</td>
          <td class="paramname"><em>name</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Sets the name of the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">name</td><td>The name to assign to this network.</td></tr>
  </table>
  </dd>
</dl>
<p>Set the name of the network so that it can be associated with a built engine. The <code>name</code> must be a zero delimited C-style string of length no greater than 128 characters. TensorRT makes no use of this string except storing it as part of the engine so that it may be retrieved at runtime. A name unique to the builder will be generated by default.</p>
<p>This method copies the name string.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_network_definition.html#ae6b53187d680c53e89c19cd39bc66beb" title="Returns the name associated with the network. ">INetworkDefinition::getName()</a>, ISafeCudaEngine::getName()</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>none </dd></dl>

</div>
</div>
<a id="a402ad2fbbf572f592077c6c0ea12a51f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a402ad2fbbf572f592077c6c0ea12a51f">&#9670;&nbsp;</a></span>setPoolingOutputDimensionsFormula()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual TRT_DEPRECATED void nvinfer1::INetworkDefinition::setPoolingOutputDimensionsFormula </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html">IOutputDimensionsFormula</a> *&#160;</td>
          <td class="paramname"><em>formula</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Set the pooling output dimensions formula. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">formula</td><td>The formula from computing the pooling output dimensions. If null is passed, the default formula is used.</td></tr>
  </table>
  </dd>
</dl>
<p>The default formula in each dimension is (inputDim + padding * 2 - kernelSize) / stride + 1.</p>
<dl class="section warning"><dt>Warning</dt><dd>Custom output dimensions formulas are not supported with wildcard dimensions.</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="classnvinfer1_1_1_i_output_dimensions_formula.html" title="Application-implemented interface to compute layer output sizes. ">IOutputDimensionsFormula</a> <a class="el" href="classnvinfer1_1_1_i_network_definition.html#aa0c2ec41c0a88e6f69bad7fa910baea6" title="Get the pooling output dimensions formula. ">getPoolingOutputDimensionsFormula()</a> </dd></dl>

</div>
</div>
<a id="a31e43047aa9ec0021f777373a56ef3a0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a31e43047aa9ec0021f777373a56ef3a0">&#9670;&nbsp;</a></span>unmarkOutput()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void nvinfer1::INetworkDefinition::unmarkOutput </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>tensor</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>unmark a tensor as a network output. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The tensor to unmark as an output tensor.</td></tr>
  </table>
  </dd>
</dl>
<p>see <a class="el" href="classnvinfer1_1_1_i_network_definition.html#a5d2cdec24bc4a1507fc80f100e18cfe9" title="Mark a tensor as a network output. ">markOutput()</a> </p>

</div>
</div>
<a id="a9f14e1d5c28329ab51f99309b84d205c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9f14e1d5c28329ab51f99309b84d205c">&#9670;&nbsp;</a></span>unmarkOutputForShapes()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool nvinfer1::INetworkDefinition::unmarkOutputForShapes </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classnvinfer1_1_1_i_tensor.html">ITensor</a> &amp;&#160;</td>
          <td class="paramname"><em>tensor</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Undo markOutputForShapes. </p>
<dl class="section warning"><dt>Warning</dt><dd>inputs to addShape cannot contain wildcard dimension values.</dd></dl>
<dl class="section return"><dt>Returns</dt><dd>True if successful, false if tensor is not marked as an output. </dd></dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li><a class="el" href="_nv_infer_8h_source.html">NvInfer.h</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacenvinfer1.html">nvinfer1</a></li><li class="navelem"><a class="el" href="classnvinfer1_1_1_i_network_definition.html">INetworkDefinition</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
